{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> TensorFlow Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science & Artificial Intelligence Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Seonwoo Min, September 2017\n",
    "\n",
    "### Some helpful tutorials and references for TensorFlow Basics:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [1] TensorFlow official tutorials: Graphs and Sessions. [[link]](https://www.tensorflow.org/programmers_guide/graphs)\n",
    "- [2] TensorFlow official tutorials: Saving and Restore. [[link]](https://www.tensorflow.org/programmers_guide/saved_model)\n",
    "- [3] TensorFlow official tutorials: Exporting and Importing a MetaGraph. [[link]](https://www.tensorflow.org/api_guides/python/meta_graph)\n",
    "- [4] Danijar Hafner. \"Structing Your TensorFlow Models\" [[link]](https://danijar.com/structuring-your-tensorflow-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load datasets (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#Matplotlib configurations\n",
    "plt.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "    \n",
    "#TensorFlow configureations\n",
    "conf = tf.ConfigProto()\n",
    "conf.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./DATA/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./DATA/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./DATA/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd69add7e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.examples.tutorials.mnist.input_data.read_data_sets(\"./DATA\")\n",
    "X_train = mnist.train.images.reshape(-1, 28, 28)\n",
    "Y_train = mnist.train.labels\n",
    "X_val = mnist.test.images.reshape(-1, 28, 28)\n",
    "Y_val = mnist.test.labels\n",
    "\n",
    "#Show MNIST data examples\n",
    "idx = 0\n",
    "for i in range(10):\n",
    "    while(1):\n",
    "        if Y_train[idx] == i:\n",
    "            break\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_train[idx], cmap='gray')\n",
    "    plt.title(i)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Structuring your TensorFlow model using python class\n",
    "\n",
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model as a class\n",
    "# It includes our model architecture, loss function, optimizer, and evaluation metrics\n",
    "class simple_model(object):\n",
    "    def __init__(self):\n",
    "        # Define input variables \n",
    "        self.inputs = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "        self.targets = tf.placeholder(tf.int64, [None])\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        # Define model architecture\n",
    "        with tf.variable_scope('L1'):\n",
    "            L1 = tf.contrib.layers.flatten(self.inputs)\n",
    "            L1 = tf.layers.dense(L1, 80, activation=tf.nn.relu)\n",
    "        with tf.variable_scope('L2'):\n",
    "            L2 = tf.layers.dense(L1, 40, activation=tf.nn.relu)\n",
    "        with tf.variable_scope('Output'):\n",
    "            self.outputs = tf.layers.dense(L2, 10, activation=None)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.outputs, labels=tf.one_hot(self.targets,10)), name=\"loss\")\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(self.loss)\n",
    "        \n",
    "        # Variables for evaluation\n",
    "        corr = tf.equal(self.targets, tf.argmax(self.outputs,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(corr, tf.float32), name='accuracy')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to train and evaluata a model\n",
    "# You can reuse this function throughout the assignment\n",
    "def run_model(session, model, X, Y, epochs=1, batch_size=500, is_training=False):\n",
    "    # For training the model\n",
    "    if is_training:\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            # Iterate over the entire dataset\n",
    "            for i in range(int(X.shape[0] / batch_size)):\n",
    "                _, cost_val = sess.run([model.optimizer, model.loss], \n",
    "                                       feed_dict={model.inputs: X[i*batch_size:(i+1)*batch_size],\n",
    "                                                  model.targets: Y[i*batch_size:(i+1)*batch_size],\n",
    "                                                  model.is_training: is_training})\n",
    "                total_loss += cost_val\n",
    "            print(\"Epoch: %02d \\t Average loss: %.4f\" % (epoch+1, total_loss / X.shape[0] * batch_size))\n",
    "        print(\"Training done!\")\n",
    "\n",
    "    # Evaluate loss and accuracy of the model\n",
    "    else:\n",
    "        loss, accuracy = 0.0, 0.0\n",
    "        for i in range(int(X.shape[0] / batch_size)):\n",
    "            l, a = sess.run([model.loss, model.accuracy],\n",
    "                            feed_dict={model.inputs: X[i*batch_size:(i+1)*batch_size],\n",
    "                                       model.targets: Y[i*batch_size:(i+1)*batch_size],\n",
    "                                       model.is_training: is_training})\n",
    "            loss += l\n",
    "            accuracy += a\n",
    "        return (loss / (X.shape[0] / batch_size), accuracy / (X.shape[0] / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 \t Average loss: 2.0922\n",
      "Epoch: 02 \t Average loss: 1.5083\n",
      "Epoch: 03 \t Average loss: 1.0474\n",
      "Epoch: 04 \t Average loss: 0.7951\n",
      "Epoch: 05 \t Average loss: 0.6583\n",
      "Epoch: 06 \t Average loss: 0.5749\n",
      "Epoch: 07 \t Average loss: 0.5191\n",
      "Epoch: 08 \t Average loss: 0.4793\n",
      "Epoch: 09 \t Average loss: 0.4495\n",
      "Epoch: 10 \t Average loss: 0.4264\n",
      "Epoch: 11 \t Average loss: 0.4077\n",
      "Epoch: 12 \t Average loss: 0.3924\n",
      "Epoch: 13 \t Average loss: 0.3795\n",
      "Epoch: 14 \t Average loss: 0.3684\n",
      "Epoch: 15 \t Average loss: 0.3587\n",
      "Epoch: 16 \t Average loss: 0.3500\n",
      "Epoch: 17 \t Average loss: 0.3423\n",
      "Epoch: 18 \t Average loss: 0.3353\n",
      "Epoch: 19 \t Average loss: 0.3290\n",
      "Epoch: 20 \t Average loss: 0.3231\n",
      "Training done!\n",
      "(Loss, Accuracy) on Training Dataset (0.3194, 0.91)\n",
      "(Loss, Accuracy) on Validataion Dataset (0.3115, 0.91)\n"
     ]
    }
   ],
   "source": [
    "# Clear old variables\n",
    "tf.reset_default_graph()    \n",
    "\n",
    "# Declare simple model\n",
    "model = simple_model()    \n",
    "    \n",
    "# Now, train and evaluate the model\n",
    "with tf.Session(config=conf) as sess:   \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    run_model(sess, model, X_train, Y_train, epochs=20, is_training=True)\n",
    "    print(\"(Loss, Accuracy) on Training Dataset (%.4f, %.2f)\" % run_model(sess, model, X_train, Y_train))\n",
    "    print(\"(Loss, Accuracy) on Validataion Dataset (%.4f, %.2f)\" % run_model(sess, model, X_val, Y_val))\n",
    "    \n",
    "    #Save your final model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, \"./model_checkpoints/model_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TensorFlow model save & restore\n",
    "\n",
    "The TensorFlow save method saves three kinds of files-.meta, .data, .index- because it stores the **graph structure** separately from the **variable values**. The *.meta* file describes the saved graph structure, so you need to import it before restoring the checkpoint (otherwise it doesn't know what variables the saved checkpoint values correspond to). *.data* stores the values of each variable in the graph, and *.index* identifies the checkpiont. Hence all the three kinds of files are required when loading your model.\n",
    "\n",
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints/model_final\n",
      "(Loss, Accuracy) on Test Dataset (1.6962, 0.57)\n"
     ]
    }
   ],
   "source": [
    "# Clear old variables\n",
    "tf.reset_default_graph()  \n",
    "\n",
    "with tf.Session(config=conf) as sess:\n",
    "    #Load your final model\n",
    "    model = simple_model()  \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"./model_checkpoints/model_final\")\n",
    "    print(\"(Loss, Accuracy) on Test Dataset (%.4f, %.2f)\" % run_model(sess, model, X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load with a var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L1/dense/kernel', 'L1/dense/bias', 'L2/dense/kernel', 'L2/dense/bias', 'Output/dense/kernel', 'Output/dense/bias']\n",
      "['L1/dense/kernel', 'L1/dense/bias', 'L2/dense/kernel', 'L2/dense/bias', 'Output/dense/kernel', 'Output/dense/bias', 'Additionl_Variable']\n",
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints/model_final\n",
      "(Loss, Accuracy) on Test Dataset (1.6962, 0.57)\n"
     ]
    }
   ],
   "source": [
    "# Clear old variables\n",
    "tf.reset_default_graph()  \n",
    "\n",
    "with tf.Session(config=conf) as sess:\n",
    "    #Variables in your model\n",
    "    model = simple_model()  \n",
    "    var_list = [v for v in tf.trainable_variables()]\n",
    "    var_list_names = [v.op.name for v in tf.trainable_variables()]\n",
    "    print(var_list_names)\n",
    "    \n",
    "    #Additional variable\n",
    "    tf.get_variable(\"Additionl_Variable\", 10)\n",
    "    var_list_new = [v.op.name for v in tf.trainable_variables()]\n",
    "    print(var_list_new)\n",
    "    \n",
    "    #Restore with a var_list\n",
    "    saver = tf.train.Saver(var_list = var_list)\n",
    "    saver.restore(sess, \"./model_checkpoints/model_final\")\n",
    "    \n",
    "    print(\"(Loss, Accuracy) on Test Dataset (%.4f, %.2f)\" % run_model(sess, model, X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load with a MetaGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints/model_final\n",
      "['save/RestoreV2/shape_and_slices:0', 'save/RestoreV2/tensor_names:0', 'save/SaveV2/shape_and_slices:0', 'save/SaveV2/tensor_names:0', 'save/Const:0', 'save/RestoreV2:0', 'Const_1:0', 'ArgMax/dimension:0', 'GradientDescent/learning_rate:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1/dim:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims/dim:0', 'gradients/loss_grad/Maximum/y:0', 'gradients/loss_grad/Const_1:0', 'gradients/loss_grad/Const:0', 'gradients/loss_grad/Shape_2:0', 'gradients/loss_grad/Prod_1:0', 'gradients/loss_grad/Maximum:0', 'gradients/loss_grad/Reshape/shape:0', 'gradients/grad_ys_0:0', 'gradients/Shape:0', 'gradients/Fill:0', 'gradients/loss_grad/Reshape:0', 'Const:0', 'softmax_cross_entropy_with_logits_sg/Slice_2/begin:0', 'softmax_cross_entropy_with_logits_sg/Sub_2/y:0', 'softmax_cross_entropy_with_logits_sg/concat_1/axis:0', 'softmax_cross_entropy_with_logits_sg/concat_1/values_0:0', 'softmax_cross_entropy_with_logits_sg/Slice_1/size:0', 'softmax_cross_entropy_with_logits_sg/Sub_1/y:0', 'softmax_cross_entropy_with_logits_sg/Rank_2:0', 'softmax_cross_entropy_with_logits_sg/Sub_1:0', 'softmax_cross_entropy_with_logits_sg/Slice_1/begin:0', 'softmax_cross_entropy_with_logits_sg/concat/axis:0', 'softmax_cross_entropy_with_logits_sg/concat/values_0:0', 'softmax_cross_entropy_with_logits_sg/Slice/size:0', 'softmax_cross_entropy_with_logits_sg/Sub/y:0', 'softmax_cross_entropy_with_logits_sg/Rank_1:0', 'softmax_cross_entropy_with_logits_sg/Sub:0', 'softmax_cross_entropy_with_logits_sg/Slice/begin:0', 'softmax_cross_entropy_with_logits_sg/Rank:0', 'softmax_cross_entropy_with_logits_sg/Sub_2:0', 'softmax_cross_entropy_with_logits_sg/Slice_2/size:0', 'one_hot/depth:0', 'one_hot/off_value:0', 'one_hot/on_value:0', 'Output/dense/bias:0', 'save/Assign_4:0', 'Output/dense/bias/read:0', 'Output/dense/bias/Initializer/zeros:0', 'Output/dense/bias/Assign:0', 'Output/dense/kernel:0', 'save/Assign_5:0', 'Output/dense/kernel/read:0', 'Output/dense/kernel/Initializer/random_uniform/max:0', 'Output/dense/kernel/Initializer/random_uniform/min:0', 'Output/dense/kernel/Initializer/random_uniform/sub:0', 'Output/dense/kernel/Initializer/random_uniform/shape:0', 'Output/dense/kernel/Initializer/random_uniform/RandomUniform:0', 'Output/dense/kernel/Initializer/random_uniform/mul:0', 'Output/dense/kernel/Initializer/random_uniform:0', 'Output/dense/kernel/Assign:0', 'L2/dense/bias:0', 'save/Assign_2:0', 'L2/dense/bias/read:0', 'L2/dense/bias/Initializer/zeros:0', 'L2/dense/bias/Assign:0', 'L2/dense/kernel:0', 'save/Assign_3:0', 'L2/dense/kernel/read:0', 'L2/dense/kernel/Initializer/random_uniform/max:0', 'L2/dense/kernel/Initializer/random_uniform/min:0', 'L2/dense/kernel/Initializer/random_uniform/sub:0', 'L2/dense/kernel/Initializer/random_uniform/shape:0', 'L2/dense/kernel/Initializer/random_uniform/RandomUniform:0', 'L2/dense/kernel/Initializer/random_uniform/mul:0', 'L2/dense/kernel/Initializer/random_uniform:0', 'L2/dense/kernel/Assign:0', 'L1/dense/bias:0', 'save/Assign:0', 'L1/dense/bias/read:0', 'L1/dense/bias/Initializer/zeros:0', 'L1/dense/bias/Assign:0', 'L1/dense/kernel:0', 'save/Assign_1:0', 'save/restore_all:0', 'save/SaveV2:0', 'save/control_dependency:0', 'L1/dense/kernel/read:0', 'L1/dense/kernel/Initializer/random_uniform/max:0', 'L1/dense/kernel/Initializer/random_uniform/min:0', 'L1/dense/kernel/Initializer/random_uniform/sub:0', 'L1/dense/kernel/Initializer/random_uniform/shape:0', 'L1/dense/kernel/Initializer/random_uniform/RandomUniform:0', 'L1/dense/kernel/Initializer/random_uniform/mul:0', 'L1/dense/kernel/Initializer/random_uniform:0', 'L1/dense/kernel/Assign:0', 'init:0', 'L1/Flatten/flatten/Reshape/shape/1:0', 'L1/Flatten/flatten/strided_slice/stack_2:0', 'L1/Flatten/flatten/strided_slice/stack_1:0', 'L1/Flatten/flatten/strided_slice/stack:0', 'Placeholder_2:0', 'Placeholder_1:0', 'one_hot:0', 'softmax_cross_entropy_with_logits_sg/labels_stop_gradient:0', 'softmax_cross_entropy_with_logits_sg/Shape_2:0', 'softmax_cross_entropy_with_logits_sg/Slice_1:0', 'softmax_cross_entropy_with_logits_sg/concat_1:0', 'softmax_cross_entropy_with_logits_sg/Reshape_1:0', 'Placeholder:0', 'L1/Flatten/flatten/Shape:0', 'L1/Flatten/flatten/strided_slice:0', 'L1/Flatten/flatten/Reshape/shape:0', 'L1/Flatten/flatten/Reshape:0', 'L1/dense/MatMul:0', 'L1/dense/BiasAdd:0', 'L1/dense/Relu:0', 'L2/dense/MatMul:0', 'L2/dense/BiasAdd:0', 'L2/dense/Relu:0', 'Output/dense/MatMul:0', 'Output/dense/BiasAdd:0', 'ArgMax:0', 'Equal:0', 'Cast:0', 'accuracy:0', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Shape:0', 'softmax_cross_entropy_with_logits_sg/Shape_1:0', 'softmax_cross_entropy_with_logits_sg/Slice:0', 'softmax_cross_entropy_with_logits_sg/concat:0', 'softmax_cross_entropy_with_logits_sg/Reshape:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/LogSoftmax:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/Neg:0', 'softmax_cross_entropy_with_logits_sg:0', 'gradients/zeros_like:0', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Shape:0', 'softmax_cross_entropy_with_logits_sg/Shape:0', 'softmax_cross_entropy_with_logits_sg/Slice_2:0', 'softmax_cross_entropy_with_logits_sg/Reshape_2:0', 'gradients/loss_grad/Shape_1:0', 'gradients/loss_grad/Prod:0', 'gradients/loss_grad/floordiv:0', 'gradients/loss_grad/Cast:0', 'gradients/loss_grad/Shape:0', 'gradients/loss_grad/Tile:0', 'gradients/loss_grad/truediv:0', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul_1:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency_1:0', 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency:0', 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape:0', 'gradients/Output/dense/BiasAdd_grad/BiasAddGrad:0', 'gradients/Output/dense/BiasAdd_grad/tuple/group_deps:0', 'gradients/Output/dense/BiasAdd_grad/tuple/control_dependency_1:0', 'GradientDescent/update_Output/dense/bias/ApplyGradientDescent:0', 'gradients/Output/dense/BiasAdd_grad/tuple/control_dependency:0', 'gradients/Output/dense/MatMul_grad/MatMul_1:0', 'gradients/Output/dense/MatMul_grad/MatMul:0', 'gradients/Output/dense/MatMul_grad/tuple/group_deps:0', 'gradients/Output/dense/MatMul_grad/tuple/control_dependency_1:0', 'GradientDescent/update_Output/dense/kernel/ApplyGradientDescent:0', 'gradients/Output/dense/MatMul_grad/tuple/control_dependency:0', 'gradients/L2/dense/Relu_grad/ReluGrad:0', 'gradients/L2/dense/BiasAdd_grad/BiasAddGrad:0', 'gradients/L2/dense/BiasAdd_grad/tuple/group_deps:0', 'gradients/L2/dense/BiasAdd_grad/tuple/control_dependency_1:0', 'GradientDescent/update_L2/dense/bias/ApplyGradientDescent:0', 'gradients/L2/dense/BiasAdd_grad/tuple/control_dependency:0', 'gradients/L2/dense/MatMul_grad/MatMul_1:0', 'gradients/L2/dense/MatMul_grad/MatMul:0', 'gradients/L2/dense/MatMul_grad/tuple/group_deps:0', 'gradients/L2/dense/MatMul_grad/tuple/control_dependency_1:0', 'GradientDescent/update_L2/dense/kernel/ApplyGradientDescent:0', 'gradients/L2/dense/MatMul_grad/tuple/control_dependency:0', 'gradients/L1/dense/Relu_grad/ReluGrad:0', 'gradients/L1/dense/BiasAdd_grad/BiasAddGrad:0', 'gradients/L1/dense/BiasAdd_grad/tuple/group_deps:0', 'gradients/L1/dense/BiasAdd_grad/tuple/control_dependency_1:0', 'GradientDescent/update_L1/dense/bias/ApplyGradientDescent:0', 'gradients/L1/dense/BiasAdd_grad/tuple/control_dependency:0', 'gradients/L1/dense/MatMul_grad/MatMul_1:0', 'gradients/L1/dense/MatMul_grad/MatMul:0', 'gradients/L1/dense/MatMul_grad/tuple/group_deps:0', 'gradients/L1/dense/MatMul_grad/tuple/control_dependency_1:0', 'GradientDescent/update_L1/dense/kernel/ApplyGradientDescent:0', 'GradientDescent:0', 'gradients/L1/dense/MatMul_grad/tuple/control_dependency:0', 'loss:0']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (500, 28, 28) for Tensor 'save/RestoreV2/shape_and_slices:0', which has shape '(6,)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6739a9e88f5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                         feed_dict={op_names[0]: X_val[i*batch_size:(i+1)*batch_size],\n\u001b[1;32m     17\u001b[0m                                    \u001b[0mop_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                    op_names[2]: False})\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1111\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1112\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (500, 28, 28) for Tensor 'save/RestoreV2/shape_and_slices:0', which has shape '(6,)'"
     ]
    }
   ],
   "source": [
    "# Clear old variables\n",
    "tf.reset_default_graph()  \n",
    "\n",
    "with tf.Session(config=conf) as sess:\n",
    "    #Restore from MetaGraph\n",
    "    saver = tf.train.import_meta_graph('./model_checkpoints/model_final.meta')\n",
    "    saver.restore(sess, \"./model_checkpoints/model_final\")\n",
    "\n",
    "    op_names = [op.name+\":0\" for op in tf.get_default_graph().get_operations()]     \n",
    "    print(op_names)\n",
    "    \n",
    "    batch_size = 500\n",
    "    loss, accuracy = 0.0, 0.0\n",
    "    for i in range(int(X_val.shape[0] / batch_size)):\n",
    "        l, a = sess.run([op_names[103], op_names[172]],\n",
    "                        feed_dict={op_names[0]: X_val[i*batch_size:(i+1)*batch_size],\n",
    "                                   op_names[1]: Y_val[i*batch_size:(i+1)*batch_size],\n",
    "                                   op_names[2]: False})\n",
    "        loss += l\n",
    "        accuracy += a\n",
    "    print(\"(Loss, Accuracy) on Test Dataset (%.4f, %.2f)\" % (loss / (X_val.shape[0] / batch_size), accuracy / (X_val.shape[0] / batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
